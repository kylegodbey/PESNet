{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PESNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "QIKGvrdOCaF8",
        "outputId": "fc32d8a5-dd5a-436a-e953-bef27931af19"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "import numpy as np\r\n",
        "import h5py\r\n",
        "import pandas as pd\r\n",
        "import sklearn.linear_model as skl\r\n",
        "from pylab import plt, mpl\r\n",
        "from sklearn.externals import joblib\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\r\n",
        "from sklearn.metrics import confusion_matrix, classification_report\r\n",
        "\r\n",
        "plt.style.use('seaborn')\r\n",
        "mpl.rcParams['font.family'] = 'serif'\r\n",
        "\r\n",
        "def MakePlot(x,y, styles, labels, axlabels):\r\n",
        "    plt.figure(figsize=(10,6))\r\n",
        "    for i in range(len(x)):\r\n",
        "        plt.plot(x[i], y[i], styles[i], label = labels[i])\r\n",
        "        plt.xlabel(axlabels[0])\r\n",
        "        plt.ylabel(axlabels[1])\r\n",
        "    plt.legend(loc=0)\r\n",
        "    \r\n",
        "# R2 metric for tensorflow from https://jmlb.github.io/ml/2017/03/20/CoeffDetermination_CustomMetric4Keras/\r\n",
        "def R2(y_true, y_pred):\r\n",
        "    SS_res =  K.sum(K.square( y_true-y_pred )) \r\n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \r\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\r\n",
        "\r\n",
        "# Where to save the figures and data files\r\n",
        "PROJECT_ROOT_DIR = \"Results\"\r\n",
        "FIGURE_ID = \"Results/FigureFiles\"\r\n",
        "DATA_ID = \"Data/\"\r\n",
        "\r\n",
        "if not os.path.exists(PROJECT_ROOT_DIR):\r\n",
        "    os.mkdir(PROJECT_ROOT_DIR)\r\n",
        "\r\n",
        "if not os.path.exists(FIGURE_ID):\r\n",
        "    os.makedirs(FIGURE_ID)\r\n",
        "\r\n",
        "if not os.path.exists(DATA_ID):\r\n",
        "    os.makedirs(DATA_ID)\r\n",
        "\r\n",
        "def image_path(fig_id):\r\n",
        "    return os.path.join(FIGURE_ID, fig_id)\r\n",
        "\r\n",
        "def data_path(dat_id):\r\n",
        "    return os.path.join(DATA_ID, dat_id)\r\n",
        "\r\n",
        "def save_fig(fig_id):\r\n",
        "    plt.savefig(image_path(fig_id) + \".png\", format='png')\r\n",
        "\r\n",
        "infile = open(data_path(\"All.dat\"),'r')\r\n",
        "\r\n",
        "# Read the experimental data with Pandas\r\n",
        "# Masses = pd.read_fwf(infile, usecols=(2,3,4,6,11),\r\n",
        "#               names=('N', 'Z', 'A', 'Element', 'Ebinding'),\r\n",
        "#               widths=(1,3,5,5,5,1,3,4,1,13,11,11,9,1,2,11,9,1,3,1,12,11,1),\r\n",
        "#               header=39,\r\n",
        "#               index_col=False)\r\n",
        "PES = pd.read_csv(infile,delim_whitespace=True,low_memory=False)\r\n",
        "\r\n",
        "print(PES)\r\n",
        "\r\n",
        "A = PES['A']\r\n",
        "Z = PES['Z']\r\n",
        "Q20 = PES['Q20']\r\n",
        "Q30 = PES['Q30']\r\n",
        "E = PES['HFB_cubic']\r\n",
        "\r\n",
        "# Build input array\r\n",
        "xx = (A.to_numpy(),Z.to_numpy(),Q20.to_numpy(),Q30.to_numpy())\r\n",
        "xx = np.asarray(xx)\r\n",
        "xx = xx.T\r\n",
        "\r\n",
        "yy = np.asarray(E).reshape(-1, 1)\r\n",
        "\r\n",
        "# Get a test set for later\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(xx,yy,test_size=0.2,random_state=42)\r\n",
        "\r\n",
        "# Scale input\r\n",
        "\r\n",
        "xscaler = MinMaxScaler()\r\n",
        "xscaler.fit(x_train)\r\n",
        "\r\n",
        "xs_train = xscaler.transform(x_train)\r\n",
        "xs_test = xscaler.transform(x_test)\r\n",
        "xs_full = xscaler.transform(xx)\r\n",
        "\r\n",
        "yscaler = MinMaxScaler()\r\n",
        "yscaler.fit(y_train)\r\n",
        "\r\n",
        "ys_train = yscaler.transform(y_train)\r\n",
        "ys_test = yscaler.transform(y_test)\r\n",
        "ys_full = yscaler.transform(yy)\r\n",
        "\r\n",
        "nodes = 50\r\n",
        "activation=\"relu\"\r\n",
        "model=tf.keras.Sequential() #Define the model object\r\n",
        "model.add(tf.keras.layers.Dense(nodes,input_shape=(4,),activation=activation)) #Add the hidden layer\r\n",
        "model.add(tf.keras.layers.Dense(nodes,input_shape=(nodes,),activation=activation)) #Add the hidden layer\r\n",
        "model.add(tf.keras.layers.Dense(nodes,input_shape=(nodes,),activation=activation)) #Add the hidden layer\r\n",
        "model.add(tf.keras.layers.Dense(nodes,input_shape=(nodes,),activation=activation)) #Add the hidden layer\r\n",
        "model.add(tf.keras.layers.Dense(1)) #Add the output layer\r\n",
        "model.compile(tf.keras.optimizers.Adam(lr=0.00001),loss='mean_squared_error',metrics=[R2]) #Adam optimizer and mean squared error loss\r\n",
        "#model.compile(tf.keras.optimizers.Adadelta(),loss='mean_squared_error',metrics=[R2]) #Adam optimizer and mean squared error loss\r\n",
        "results=model.fit(xs_train,ys_train,epochs=50, batch_size=8, validation_split=0.2,verbose=1)\r\n",
        "history = results.history\r\n",
        "plt.plot(history[\"loss\"], label=\"training loss\")\r\n",
        "plt.plot(history[\"val_loss\"], label=\"validation loss\")\r\n",
        "plt.xlabel(\"Epoch\")\r\n",
        "plt.ylabel(\"Loss\")\r\n",
        "plt.legend()\r\n",
        "plt.ylim(0,1)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# test loss calculation\r\n",
        "\r\n",
        "[test_loss,test_R2]=model.evaluate(xs_test, ys_test, verbose=1)\r\n",
        "\r\n",
        "print('Test Loss: {:.04}'.format(test_loss))\r\n",
        "print('Test R2: {:.04}'.format(test_R2))\r\n",
        "\r\n",
        "testen_out=model.predict(xs_test)\r\n",
        "trainen_out=model.predict(xs_train)\r\n",
        "fullen_out=model.predict(xs_full)\r\n",
        "\r\n",
        "# test loss calculation\r\n",
        "\r\n",
        "[test_loss,test_R2]=model.evaluate(xs_test, ys_test, verbose=1)\r\n",
        "\r\n",
        "print('Test Loss: {:.04}'.format(test_loss))\r\n",
        "print('Test R2: {:.04}'.format(test_R2))\r\n",
        "\r\n",
        "testen_out=model.predict(xs_test)\r\n",
        "trainen_out=model.predict(xs_train)\r\n",
        "fullen_out=model.predict(xs_full)\r\n",
        "\r\n",
        "# Shift back for plotting\r\n",
        "\r\n",
        "x_train = xscaler.inverse_transform(xs_train)\r\n",
        "x_test = xscaler.inverse_transform(xs_test)\r\n",
        "x_full = xscaler.inverse_transform(xs_full)\r\n",
        "\r\n",
        "trainen_out = yscaler.inverse_transform(trainen_out).T.squeeze()\r\n",
        "testen_out = yscaler.inverse_transform(testen_out).T.squeeze()\r\n",
        "fullen_out = yscaler.inverse_transform(fullen_out).T.squeeze()\r\n",
        "\r\n",
        "a_test=np.sum(x_test,axis=1)\r\n",
        "a_train=np.sum(x_train,axis=1)\r\n",
        "a_full=np.sum(x_full,axis=1)\r\n",
        "\r\n",
        "en_test=np.asarray(y_test).squeeze()\r\n",
        "trainen_test=np.asarray(y_train).squeeze()\r\n",
        "fullen_test=np.asarray(yy).squeeze()\r\n",
        "\r\n",
        "diff = en_test-testen_out\r\n",
        "traindiff = trainen_test-trainen_out\r\n",
        "fulldiff = fullen_test-fullen_out\r\n",
        "\r\n",
        "diff = np.asarray(diff.T).squeeze()\r\n",
        "fulldiff = np.asarray(fulldiff.T).squeeze()\r\n",
        "traindiff = np.asarray(traindiff.T).squeeze()\r\n",
        "\r\n",
        "x_test_even = x_test[(np.rint(x_test[:,0])%2==0) & (np.rint(x_test[:,1])%2==0)]\r\n",
        "diff_even = diff[(np.rint(x_test[:,0])%2==0) & (np.rint(x_test[:,1])%2==0)]\r\n",
        "x_train_even = x_train[(np.rint(x_train[:,0])%2==0) & (np.rint(x_train[:,1])%2==0)]\r\n",
        "traindiff_even = traindiff[(np.rint(x_train[:,0])%2==0) & (np.rint(x_train[:,1])%2==0)]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          Q20   Q30  HFB_cubic      A      Z\n",
            "0         0.0   0.0   2.079800  218.0   94.0\n",
            "1         0.0   3.0   2.679000  218.0   94.0\n",
            "2         0.0   6.0   4.473800  218.0   94.0\n",
            "3         0.0   9.0   7.310141  218.0   94.0\n",
            "4         0.0  12.0  10.728700  218.0   94.0\n",
            "...       ...   ...        ...    ...    ...\n",
            "285763  250.0  48.0 -24.198464  360.0  110.0\n",
            "285764  250.0  51.0 -24.170991  360.0  110.0\n",
            "285765  250.0  54.0 -24.222222  360.0  110.0\n",
            "285766  250.0  57.0 -24.203246  360.0  110.0\n",
            "285767  250.0  60.0 -24.063370  360.0  110.0\n",
            "\n",
            "[285768 rows x 5 columns]\n",
            "Epoch 1/50\n",
            " 7200/22862 [========>.....................] - ETA: 33s - loss: 0.1717 - R2: -12.3854"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-15e67e8bb7ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Adam optimizer and mean squared error loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m#model.compile(tf.keras.optimizers.Adadelta(),loss='mean_squared_error',metrics=[R2]) #Adam optimizer and mean squared error loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}